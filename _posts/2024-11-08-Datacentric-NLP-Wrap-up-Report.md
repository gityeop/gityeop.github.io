---
title: Datacentric-NLP-Wrap-up-Report
date: 2024-11-08
categories: machine-learning
---

**임상엽**

**프로젝트 진행 계획**

1. 대회 설명에서 봤을 때 노이즈가 아스키 코드(한글이 포함X)로 이루어져있다고 해서, 전체 문자 길이에서 한글의 비율로 노이즈의 적용 여부를 알 수 있지 않을까해서 시도 해봄
2. 첫 번째 시도 결과 “…”이 비율의 많은 부분을 차지해서 “...“을 ”…” 바꿔줌

   ![Image](https://i.imgur.com/2zjfNhu.png)

3. 분류 결과: 너무 많은 노이즈 | 적당한 노이즈 | 정상 데이터 or 라벨 에러 데이터
   1. 너무 많은 노이즈는 복원이 힘들기 때문에 **제외**하기로 결정
   2. 적당한 노이즈 복원이 가능 & 라벨 에러가 없기 때문에 노이즈를 제거하여 사용하기로 결정
   3. 정상 데이터 or 라벨 에러 데이터의 경우 라벨 에러를 고쳐서 사용하기로 결정

**진행 순서**

1. 라벨 에러가 없는 적당한 노이즈의 데이터에 노이즈를 제거하여 label에 대한 정보를 추출
2. label에 대한 정보를 추출한 후 이를 바탕으로 라벨 에러 복구 or 증강

**텍스트 노이즈 복구**

```python
prompt_reasoning = ChatPromptTemplate.from_template(
"""
Prompt:

아래에 번호와 줄바꿈으로 나눠진 {batch_size}개의 텍스트는 임의의 character 중 20%~80%를 한글을 제외한 다른 아스키 코드로 대체한 텍스트가 껴있습니다. 한글을 제외한 다른 아스키 코드로 대체한 텍스트는 다음과 같습니다.
예시:
1. pI美대선I앞두고 R2fr단 발] $비해 감시 강화
2. oi 매력 R모h츠a열#w3약 >l·주가 고Q/진
아닌 예시:
1. 美성인 6명 중 1명꼴 배우자·연인 빚 떠안은 적 있다
2. 朴대통령 얼마나 많이 놀라셨어요…경주 지진현장 방문종합

출력 형식:
1. 텍스트1, 아스키 코드로 대체했다고 생각하는 근거 또는 없다고 생각하는 근거
2. 텍스트2, 아스키 코드로 대체했다고 생각하는 근거 또는 없다고 생각하는 근거
...

아래 텍스트를 확인하고, 각 텍스트에 대한 아스키 코드로 대체했는지에 대한 근거를 논리적으로 밝혀주세요. (주어진 텍스트 갯수={batch_size}):
{input}
"""
)

prompt_label = ChatPromptTemplate.from_template(
"""
{response_reasoning}

내용들의 근거들을 바탕으로 번호에 따른 텍스트에 대한 아스키 코드 대체 여부를 1 또는 0으로 분류해 주세요.
아스키 코드로 대체되었다면 1, 대체되지 않았다면 0입니다.
출력 형식을 엄격히 지키세요.

출력 형식:
1. 텍스트1: 1
2. 텍스트2: 0
...
"""
)
```

두 단계의 프롬프트를 작성해서 텍스트에 노이즈가 있는지 없는지를 검증

- 노이즈가 있다고 판단한 데이터의 갯수: 1666
- 대회 측에서 제공한 노이즈가 있는 데이터의 갯수: 1600

gemma2 오픈 소스 모델로 꽤나 좋은 성능으로 분류해낸 것을 확인

**라벨 에러 복구**

clustering으로 하는 방식과 llm을 사용해서 라벨 에러를 고치는 작업을 진행함

<iframe width="560" height="315" src="https://www.youtube.com/embed/3m0wHz-PYVU?si=UOGgSRqSmaUAOCNh" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

**Clustering Visualization with PCA**

라벨 에러 복구 작업 전에 클러스터링 결과를 시각화하여 레이블 오류를 검토하고 데이터의 패턴을 파악하기 위해 **PCA**를 활용

PCA는 고차원의 데이터를 저차원 공간으로 투영하여 시각적 분석을 쉽게 할 수 있는 방법

**Outlier Detection Using Silhouette Score**

클러스터의 데이터 간의 응집도와 클러스터 간의 분리도를 평가할 수 있는 실루엣 점수로 아웃라이어를 감지해서 아웃라이어를 새로운 클러스터에 할당하였다.

결과는 기존에 사용했던 데이터의 성능보다 떨어졌다. 생각되는 이유는 클러스터링을 할 때 잘못된 라벨의 데이터가 있어서 클러스터링이 잘못되었을 경우와, 아웃라이어를 새로운 클러스터에 할당하면서 원래 클러스터에 잘 속해있던 데이터도 새로운 클러스터에 포함되었을 것으로 판단된다.

추가로 클러스터링을 하면서 3번에 해당하는 사회 주제가 매우 넓은 범위에 위치하고 있어서 모델이 사회 주제를 잘맞추지 못하는 것을 발견했다.

**데이터 증강**

이상치 탐지에서 발견한 결과를 데이터 증강에 확인하기 위해 사회 주제의 데이터를 증강하였다.

증강의 과정은 LLM을 활용해서 얻어낸 라벨에 대한 정보와 주제에 해당하는 텍스트의 하위 카테고리 태그를 추출해서 이를 다시 LLM에게 제공해 뉴스 기사 제목을 생성해내는 작업을 수행하였다.

사회 주제 데이터를 1000개 증강하여 학습에 사용한 결과 0.8519 → 0.8446로 성능이 저하하였다.

비교를 위해 경제 주제 데이터를 1000개 증강하여 학습에 사용한 결과 성능이 그대로 유지 되었는데, 이것은 생성된 사회 주제의 텍스트의 품질이나 다양성이 원본 데이터와 일치하지 않아 모델 학습에 부정적인 영향을 미쳤기 때문이라고 생각된다.
