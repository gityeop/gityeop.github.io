---
title: QA with Phrase Retrieval
date: 2024-10-27
categories: machine-learning
---

### 1. 기존 Retriever-Reader 접근법의 한계

기존 질문 응답 시스템에서는 먼저 관련 문서를 검색한 뒤, 그 문서에서 답을 찾는 과정을 거친다. 이 과정을 'Retriever-Reader' 접근법이라고 부르는데, 여기에는 몇 가지 한계가 있다. 예를 들어, "미국의 44대 대통령은 누구인가?"라는 질문에 대해 기존 방식에서는 질문과 관련된 상위 5~10개의 문서를 검색해 reader에게 전달하고, 그 안에서 답을 찾는 식이다. 하지만 이렇게 전달된 문서들이 항상 답을 포함하고 있는 것은 아니어서 '오류 전파'가 발생하기 쉽다. 즉, 잘못된 문서가 선택되면 정답을 찾기 어렵다는 것이다.

### 2. Query-Agnostic Decomposition의 핵심 개념

이러한 문제를 해결하기 위해 제안된 방법 중 하나가 Query-Agnostic Decomposition이다. Query-Agnostic Decomposition은 '질문에 독립적인 분해'라는 의미다. 쉽게 말해, 질문 $q$와 답 $a$, 그리고 문서 $d$를 각각 분리하여 인코딩하는 방식이다. 기존에는 질문과 문서를 함께 인코딩해서 정답을 찾아야 했기 때문에, 질문이 바뀌면 모든 작업을 처음부터 다시 해야 했다. 하지만 Query-Agnostic Decomposition을 사용하면 질문과 문서, 답을 독립적으로 처리할 수 있어 효율성이 높아진다.

이를 수식으로 보면,

$$
\hat{a} = \arg\max F_{\theta}(a, q, d)
$$

여기서 $F_{\theta}$는 모델을 의미하며, 질문 $q$, 답 $a$, 문서 $d$를 모두 인코딩하여 최적의 답을 찾는 방식이다. 이 수식은 기존의 Retriever-Reader 방식과 유사하다. 모든 요소가 함께 인코딩되기 때문에, 질문이 바뀌면 모든 것을 다시 인코딩해야 하는 단점이 있다.

하지만 다음 수식처럼 Query-Agnostic Decomposition에서는,

$$
\hat{a} = \arg\max G_{\theta}(q) \cdot H_{\theta}(a, d)
$$

여기서 $G_{\theta}(q)$는 질문에 대한 인코딩, $H_{\theta}(a, d)$는 문서와 답에 대한 인코딩이다. 이렇게 질문과 문서를 독립적으로 인코딩하게 되면, 질문만 바뀔 때 전체 과정을 반복할 필요 없이 질문에 대한 인코딩만 새로 하면 된다.

### 3. Phrase Indexing으로 한계 극복하기

이렇게 Query-Agnostic Decomposition을 통해 질문과 문서의 인코딩을 분리한 다음, 이를 Phrase Indexing 기법과 결합하여 효율성을 더욱 높일 수 있다. 여기서 핵심 아이디어는 두 단계로 나누어 문서를 검색하고 답을 찾는 방식이 아니라, 질문에 대해 정답이 되는 구문(phrase)을 바로 검색하는 것이다. 예를 들어 "미국의 44대 대통령은 누구인가?"라는 질문이 주어졌을 때, 기존 방식처럼 여러 문서를 읽는 것이 아니라 "Barack Obama"라는 답을 바로 검색해 낼 수 있다면 훨씬 효율적일 것이다.

이 방법에서는 각 문장에서 중요한 구문들을 '인덱싱'해 둔다. 예를 들어 "Barack Obama (1961-present) was the 44th President of the United States."라는 문장이 있다고 하면, 이 문장에서 중요한 정보인 "Barack Obama", "(1961-present)", "44th President", "United States" 같은 구문들을 인덱싱해 둔다. 이렇게 인덱싱된 구문들은 나중에 질문과 유사한 질문이 들어왔을 때 빠르게 검색할 수 있도록 해준다.

### 4. Dense와 Sparse 벡터의 사용

구문을 인덱싱할 때는 Dense와 Sparse 벡터를 모두 사용한다. Dense 벡터는 의미적인 정보, 예를 들어 문장의 의미나 맥락을 잘 표현하는데 유리하다. 반면, Sparse 벡터는 어휘적인 정보를 잘 담아낸다. 예를 들어 "Barack Obama"라는 구문을 표현할 때, Dense 벡터는 오바마가 미국 대통령이라는 의미를 포함하지만, Sparse 벡터는 단어 자체에 집중한다.

이렇게 두 가지 벡터를 결합해서 사용하면, 질문에 대한 답을 더 정확하게 찾을 수 있다. 예를 들어 "오바마는 언제 태어났나?"라는 질문이 주어졌을 때, Dense 벡터는 질문의 의미를 파악하고, Sparse 벡터는 "1961-present"라는 구문을 빠르게 찾아낼 수 있다.

### 5. 성능 및 실험 결과

이 Phrase Retrieval 방법은 기존의 Retriever-Reader 접근법에 비해 훨씬 빠르고 효율적이다. 예를 들어 SQuAD-open 데이터셋에서 기존 방식에 비해 68배 빠른 추론 속도를 보여주었고, 성능도 약간 더 높았다. 기존 방식에서는 질문과 문서, 답을 모두 함께 인코딩했지만, Phrase Retrieval 방식에서는 질문과 문서/답을 각각 인코딩한다. 이렇게 하면 질문과 문서 사이의 상호작용 정보(attention 정보)가 부족해져 성능이 떨어질 수 있지만, 새로운 방법들을 적용해 이러한 한계를 극복하려고 하고 있다.

## DenSPI와 DensePhrases

### 1. DenSPI (Dense-Sparse Phrase Index, 2019)

DenSPI는 오픈 도메인 질문 응답 시스템에서 빠르게 답을 찾아내기 위한 방법 중 하나이다. 쉽게 말해, 질문에 대한 답을 빠르게 검색하기 위해 "문장 내에서 답이 될 만한 구문들을 미리 인덱싱해 놓자"는 접근이다.

예를 들어 "미국의 44대 대통령은 누구인가?"라는 질문이 들어왔을 때, 기존 방식처럼 수많은 문서를 하나하나 읽고 답을 찾기보다는, 미리 문서에서 "Barack Obama" 같은 답이 될 만한 구문들을 인덱싱해 놓고, 질문과 매칭시켜 빠르게 정답을 찾아내는 방식이다. 이 과정에서 미리 학습된 언어 모델(BERT 등)을 이용해 Dense 벡터를 생성하고, 그 시작과 끝 지점을 표현하는 벡터(start, end vector)를 재사용함으로써 메모리 사용량을 줄인다.

다만, DenSPI에는 몇 가지 한계가 있다. 예를 들어 SQuAD 데이터셋에서 성능을 보면, 기존 Retriever-Reader 방식과 비교했을 때 성능 차이가 발생하는데, 그 이유는 질문과 문서, 그리고 답을 모두 함께 인코딩하지 않기 때문이다. 다시 말해, 질문과 문서 간의 상호작용 정보(attention)가 제대로 반영되지 못해 정확도가 떨어지는 것이다. 그래도 DenSPI는 기존 방식보다 훨씬 빠르다는 장점이 있어서 실시간 답변이 중요한 상황에서 유용하다.

### 2. DensePhrases (2021)

DensePhrases는 DenSPI의 한계를 극복하기 위해 제안된 새로운 방법이다. 이 방법은 특히 '저장 공간 문제'와 '정확도 문제'를 해결하는 데 중점을 두었다.

예를 들어, DenSPI는 질문을 처리할 때 하나의 CLS 토큰을 쪼개서 start와 end로 사용했는데, DensePhrases에서는 별도의 SpanBERT 모델을 사용해 각각 start와 end로 표현하도록 했다. 이렇게 함으로써, 질문의 시작과 끝을 명확하게 구분하고, 문맥을 더 잘 이해할 수 있게 되었다. 이 변화 덕분에 Sparse 벡터를 사용할 필요가 없어졌고, 따라서 큰 저장 공간을 필요로 하던 문제가 해결되었다. 예를 들어, DenSPI에서는 phrase를 인덱싱하기 위해 1,200GB의 저장 공간이 필요했지만, DensePhrases에서는 320GB로 이를 대폭 줄일 수 있었다.

또한 DensePhrases는 질문에 대한 답을 찾을 때 훨씬 더 빠른 속도를 자랑한다. 예를 들어, DPR(기존의 Dense Passage Retrieval) 방식과 비교했을 때 20배 빠른 속도를 보인다. 이는 실시간으로 많은 질문을 처리해야 하는 시스템에서 매우 중요한 장점이다.
