---
title: DataPerf
date: 2024-10-28
categories: machine-learning
excerpt: "데이터 중심 벤치마크"
tags: ["ai/data-centric", "ai/benchmarking", "ai/machine-learning"]
---

## DataPerf

DataPerf는 "Data"와 "Performance"의 합성어로, 데이터의 품질을 개선하여 AI 모델의 성능을 극대화하는 것을 목표로 하는 프레임워크를 의미한다. 여기서 "Data"는 AI 모델의 학습과 평가에 사용하는 모든 데이터를 의미하며, "Performance"는 모델의 예측 정확도와 같은 성능 지표를 뜻한다. DataPerf는 모델 중심이 아닌 데이터 중심의 접근법을 통해 AI 시스템의 성능을 지속적으로 향상시키는 것을 목표로 한다.

### DataPerf: Data-Centric ML의 핵심 개념과 디자인

DataPerf는 Data-Centric ML 엔지니어링의 과정을 체계적으로 정리한 벤치마크 프레임워크이다. 모델을 고정하고 데이터셋만 개선해 모델의 성능을 최대화하는 것이 핵심 목표다. Data-Centric AI가 주목받는 이유는 데이터의 품질이 AI 성능에 직접적인 영향을 미친다는 점에서, 데이터의 중요성을 재조명하고 효율적인 데이터 개선 방안을 제시하기 때문이다.

#### 1. Training Data Development (훈련 데이터 개발)

DataPerf는 훈련 데이터의 수집부터 평가까지의 전 과정을 구조화한다. **Acquisition/Creation** 단계에서는 학습에 필요한 데이터를 확보하고, **Selection** 단계에서는 유효한 데이터를 선택하여 모델 학습에 적합한 데이터셋을 구축한다. 이후 **Debugging** 단계에서는 데이터 내의 오류나 노이즈를 분석하고 수정하여 데이터의 품질을 높인다. 마지막으로 **Valuation** 단계에서는 데이터의 가치를 평가하고 데이터셋의 품질을 측정하여 모델 학습에 적합한지를 판단한다.

#### 2. Model Development (모델 개발)

DataPerf에서는 모델 개발 과정을 Architecture, Optimization, Objective로 나누어 설명한다. **Architecture** 단계에서는 모델의 구조를 정의하고, **Optimization** 단계에서는 성능을 높이기 위한 최적화 작업을 수행한다. **Objective** 단계에서는 모델이 해결해야 할 문제를 구체적으로 설정하여 모델의 목표를 명확히 한다. 그러나 Data-Centric 접근에서는 모델을 반복적으로 수정하기보다는, 모델 구조를 고정하고 데이터의 품질을 개선하는 방향으로 진행한다. 기존 벤치마크들은 대부분 모델 개발에 집중하지만, DataPerf는 데이터의 역할을 더욱 중요하게 다룬다.

#### 3. Test Data Development (테스트 데이터 개발)

테스트 데이터는 모델의 성능을 실제 환경에서 평가하기 위한 중요한 자료이다. DataPerf는 테스트 데이터 개발 과정도 훈련 데이터와 유사한 단계로 구분한다. **Acquisition/Creation**과 **Slice Discovery**를 통해 다양한 테스트 데이터를 구성하고, 이를 통해 모델이 실제 환경에서 다양한 상황을 처리할 수 있는지 확인한다. 이러한 데이터 중심의 평가를 통해 모델의 약점을 파악하고 개선할 수 있는 피드백 루프를 형성한다.

## DataPerf Benchmark Types

DataPerf의 벤치마크 타입은 AI 모델의 성능을 높이기 위해 데이터셋을 체계적이고 알고리즘적으로 변경하는 다양한 접근 방법을 제시한다. 각 벤치마크 타입에 대한 구체적인 설명과 함께 실생활에서 적용될 수 있는 예시를 들어 설명하겠다.

### 1. Training Set Creation (훈련 세트 생성)

- **벤치마크 기법**: 주어진 학습 데이터셋을 새로운 데이터셋으로 교체
- **벤치마크 지표**: 새로운 데이터셋으로 학습한 모델의 정확도

**예시**: 예를 들어, 자율 주행 AI 모델을 학습시키고 있다고 하자. 기존 데이터셋이 낮은 해상도의 사진이나 특정 시간대(낮)의 환경에만 국한되어 있다면, 새로운 데이터셋에는 더 높은 해상도의 사진과 다양한 시간대(낮, 밤, 비 오는 날 등)의 사진을 포함시킨다. 이를 통해 모델이 더 다양한 환경에서 운전할 수 있도록 성능을 개선한다.

### 2. Test Set Creation (테스트 세트 생성)

- **벤치마크 기법**: 고정된 개수의 추가 테스트 데이터셋 추가
- **벤치마크 지표**: 모델이 잘못 라벨링하고, 사람이 올바르게 라벨링한 테스트 데이터의 개수

**예시**: 이미지 분류 모델이 있다고 하자. 기존 테스트 데이터셋에는 흔한 사물만 포함되어 있었지만, 새로운 테스트 데이터셋에는 흔하지 않은 사물(예: 희귀한 새나 특정 패턴을 가진 물체)을 추가한다. 이후 모델이 이러한 추가 데이터를 얼마나 잘 분류하는지를 평가해 모델의 성능을 보완할 수 있다.

### 3. Selection Algorithm (선택 알고리즘)

- **벤치마크 기법**: 학습 데이터셋으로 subset으로 교체
- **벤치마크 지표**: subset으로 학습한 모델의 정확도

**예시**: 대규모 텍스트 데이터를 학습시키는 NLP 모델이 있다고 하자. 전체 데이터를 사용하는 대신, 특정 주제(예: 스포츠, 정치)와 관련된 텍스트만 선택하여 subset을 구성하고 모델을 학습시킨다. 이를 통해 특정 주제에 대한 모델의 정확도를 높일 수 있다.

### 4. Debugging Algorithm (디버깅 알고리즘)

- **벤치마크 기법**: 잘못된 라벨이 포함된 학습 데이터셋 식별
- **벤치마크 지표**: 식별된 라벨이 수정된 후 학습한 모델의 정확도

**예시**: 이미지 분류 모델의 학습 데이터 중 고양이를 개로 잘못 라벨링한 사례가 있다면, 이를 찾아내어 올바르게 수정한다. 이렇게 수정된 데이터로 다시 학습한 모델은 기존보다 더 정확하게 고양이와 개를 구분할 수 있게 된다.

### 5. Slicing Algorithm (슬라이싱 알고리즘)

- **벤치마크 기법**: 학습 데이터셋을 의미적으로 일관된 그룹으로 나눔
- **벤치마크 지표**: 맞는 그룹에 할당된 데이터의 개수

**예시**: 병원 데이터를 사용하는 의료 AI 모델이 있다고 하자. 데이터를 연령대별(예: 20대, 30대, 40대) 혹은 질병별(예: 고혈압, 당뇨)로 나누어 학습시키는 것이다. 이를 통해 특정 연령대나 질병에 대한 예측 정확도를 향상시킬 수 있다.

### 6. Valuation Algorithm (평가 알고리즘)

- **벤치마크 기법**: 데이터셋 A와 데이터셋 A + B에서의 훈련 정확도 개선 추정 (추정 시 B에 라벨이 없음)
- **벤치마크 지표**: 예측 정확도와 실제 정확도 간의 절대값

**예시**: 고객 리뷰 데이터를 사용하여 감성 분석을 하는 모델이 있다고 하자. 데이터셋 A는 긍정과 부정 리뷰만 포함하고 있고, 데이터셋 B는 중립 리뷰만 포함한다고 가정한다. 데이터셋 B의 라벨을 알지 못한 상태에서, A와 A+B를 사용해 모델을 학습시켜 중립적인 감정도 예측할 수 있는지 평가해본다. 이렇게 라벨이 없는 추가 데이터를 통해 모델의 감성 분석 능력을 확장할 수 있다.
