---
title: TF-IDF 이해하기
date: 2024-10-02
categories: machine-learning
excerpt: "TF-IDF 설명"
tags: ["nlp", "information-retrieval"]
---

## TF-IDF

- **TF-IDF**의 전제는 **한 문서에서는 자주 등장**하지만, **다른 문서에서는 자주 등장하지 않는 단어**를 중요하게 여기겠다는 것이다.
- **TF(t, d)**: 특정 문서에서 단어가 얼마나 자주 등장하는지를 측정.
- **IDF(t)**: 전체 문서에서 해당 단어의 희귀도를 측정.
- **TF-IDF(t, d)**: 특정 문서에서 해당 단어의 상대적인 중요도를 나타내는 값으로, 단어의 빈도와 희귀도를 동시에 고려한 값.

### 1. **TF (Term Frequency) 공식**

- 특정 문서에서 단어가 얼마나 자주 등장하는지를 나타냅니다.

  $$
  \text{TF(t, d)} = \frac{\text{Number of times term } t \text{ appears in document } d}{\text{Total number of terms in document } d}
  $$

- 예를 들어, 단어 `cat`이 문서에서 3번 등장하고, 문서 전체 단어의 수가 100개라면:
  $$
  \text{TF(cat, d)} = \frac{3}{100} = 0.03
  $$

### 2. **IDF (Inverse Document Frequency) 공식**

- 전체 문서에서 특정 단어가 얼마나 희귀한지를 나타냅니다. 단어가 여러 문서에 많이 등장할수록 그 단어의 중요도는 낮아집니다.
- 전체 문서에서 특정 단어가 얼마나 나타나는지는 다음과 같이 나타낼 수 있다.
  $$
  {\frac{\text{DF}(t)}{N}}
  $$
- 이렇게 하면 많이 등장할 수록(희귀하지 않을 수록,DF(t)의 값이 커질 수록) 값이 커진다.
- 우리는 다른 문서에 많이 등장할 수록 희귀도가 떨어짐을 표현하고 싶기 때문에 다음과 같이 역수를 취해준다.
  $$
  {\frac{N}{\text{DF}(t)}}
  $$
- 이렇게 하면 많이 등장할 수록 값이 작아지고, 곧 희귀도가 떨어진다는 것을 수학으로 표현할 수 있다.
- 그리고 전체 문서에서 모두 다 등장한 단어라면 거기에 0점이라는 희귀도 점수를 부여하는 것이 적절함으로 log를 사용하여 이를 표현해준다.
  $$
  {\log{\frac{N}{\text{DF}(t)}}}
  $$
- 마지막으로 DF(t)가 한번도 등장하지 않았다면 분모가 0이 되어버려 계산을 할 수 없으므로 +1을 해준다.
- 공식:

$$
\text{IDF(t)} = \log{\frac{N}{1 + \text{DF}(t)}}
$$

- $N$ = 전체 문서의 수
- $\text{DF}(t)$ = 단어 $t$가 등장한 문서의 수
- 분모에 1을 더하는 것은 $\text{DF}(t)$가 0인 경우를 방지하기 위해서입니다.

- 예를 들어, 전체 문서의 수가 10개이고, 단어 `cat`이 2개의 문서에 등장했다면:
  $$
  \text{IDF(cat)} = \log{\frac{10}{1 + 2}} = \log{\frac{10}{3}} \approx 0.52
  $$

### 3. **TF-IDF 공식**

- **TF-IDF**는 TF와 IDF를 곱하여 단어의 중요도를 계산합니다.
- 공식:

  $$
  \text{TF-IDF(t, d)} = \text{TF(t, d)} \times \text{IDF(t)}
  $$

- 예를 들어, 만약 `TF(cat, d) = 0.03`이고 `IDF(cat) = 0.52`라면:
  $$
  \text{TF-IDF(cat, d)} = 0.03 \times 0.52 = 0.0156
  $$

### **예시 데이터: 5개의 문장**

1. 문서 1: "The cat sat on the mat"
2. 문서 2: "The dog sat on the mat"
3. 문서 3: "The cat chased the mouse"
4. 문서 4: "The dog barked loudly"
5. 문서 5: "The mouse ran up the clock"

### 1. **TF (Term Frequency) 계산**

각 문서에서 단어의 등장 빈도를 계산하고, 그 빈도를 전체 단어 수로 나눕니다.

#### 문서 1: "The cat sat on the mat"

- 각 단어의 등장 횟수:
  - the: 2회
  - cat: 1회
  - sat: 1회
  - on: 1회
  - mat: 1회
- 전체 단어 수: 6
- 각 단어의 TF:
  - TF(the) = 2/6 ≈ 0.33
  - TF(cat) = 1/6 ≈ 0.17
  - TF(sat) = 1/6 ≈ 0.17
  - TF(on) = 1/6 ≈ 0.17
  - TF(mat) = 1/6 ≈ 0.17

#### 문서 2: "The dog sat on the mat"

- 각 단어의 등장 횟수:
  - the: 2회
  - dog: 1회
  - sat: 1회
  - on: 1회
  - mat: 1회
- 전체 단어 수: 6
- 각 단어의 TF:
  - TF(the) = 2/6 ≈ 0.33
  - TF(dog) = 1/6 ≈ 0.17
  - TF(sat) = 1/6 ≈ 0.17
  - TF(on) = 1/6 ≈ 0.17
  - TF(mat) = 1/6 ≈ 0.17

#### 문서 3: "The cat chased the mouse"

- 각 단어의 등장 횟수:
  - the: 2회
  - cat: 1회
  - chased: 1회
  - mouse: 1회
- 전체 단어 수: 5
- 각 단어의 TF:
  - TF(the) = 2/5 = 0.4
  - TF(cat) = 1/5 = 0.2
  - TF(chased) = 1/5 = 0.2
  - TF(mouse) = 1/5 = 0.2

#### 문서 4: "The dog barked loudly"

- 각 단어의 등장 횟수:
  - the: 1회
  - dog: 1회
  - barked: 1회
  - loudly: 1회
- 전체 단어 수: 4
- 각 단어의 TF:
  - TF(the) = 1/4 = 0.25
  - TF(dog) = 1/4 = 0.25
  - TF(barked) = 1/4 = 0.25
  - TF(loudly) = 1/4 = 0.25

#### 문서 5: "The mouse ran up the clock"

- 각 단어의 등장 횟수:
  - the: 2회
  - mouse: 1회
  - ran: 1회
  - up: 1회
  - clock: 1회
- 전체 단어 수: 6
- 각 단어의 TF:
  - TF(the) = 2/6 ≈ 0.33
  - TF(mouse) = 1/6 ≈ 0.17
  - TF(ran) = 1/6 ≈ 0.17
  - TF(up) = 1/6 ≈ 0.17
  - TF(clock) = 1/6 ≈ 0.17

### 2. **IDF (Inverse Document Frequency) 계산**

총 문서 수는 5개입니다. 각 단어의 IDF를 구하기 위해 단어가 등장한 문서의 수를 세어봅니다.

- **the**: 5개의 문서에 모두 등장 → IDF(the) = log(5 / (1 + 5)) = log(5 / 5) = log(1) = 0
- **cat**: 2개의 문서에 등장 → IDF(cat) = log(5 / (1 + 2)) = log(5 / 2) ≈ 0.40
- **sat**: 2개의 문서에 등장 → IDF(sat) = log(5 / (1 + 2)) = log(5 / 2) ≈ 0.40
- **on**: 2개의 문서에 등장 → IDF(on) = log(5 / (1 + 2)) = log(5 / 2) ≈ 0.40
- **mat**: 2개의 문서에 등장 → IDF(mat) = log(5 / (1 + 2)) = log(5 / 2) ≈ 0.40
- **dog**: 2개의 문서에 등장 → IDF(dog) = log(5 / (1 + 2)) = log(5 / 2) ≈ 0.40
- **chased**: 1개의 문서에 등장 → IDF(chased) = log(5 / (1 + 1)) = log(5 / 1) = log(5) ≈ 0.70
- **mouse**: 2개의 문서에 등장 → IDF(mouse) = log(5 / (1 + 2)) = log(5 / 2) ≈ 0.40
- **barked**: 1개의 문서에 등장 → IDF(barked) = log(5 / (1 + 1)) = log(5 / 1) = log(5) ≈ 0.70
- **loudly**: 1개의 문서에 등장 → IDF(loudly) = log(5 / (1 + 1)) = log(5 / 1) = log(5) ≈ 0.70
- **ran**: 1개의 문서에 등장 → IDF(ran) = log(5 / (1 + 1)) = log(5 / 1) = log(5) ≈ 0.70
- **up**: 1개의 문서에 등장 → IDF(up) = log(5 / (1 + 1)) = log(5 / 1) = log(5) ≈ 0.70
- **clock**: 1개의 문서에 등장 → IDF(clock) = log(5 / (1 + 1)) = log(5 / 1) = log(5) ≈ 0.70

### 3. **TF-IDF 계산**

이제 각 단어의 TF와 IDF를 곱하여 TF-IDF 값을 구해보겠습니다.

#### 문서 1: "The cat sat on the mat"

- TF-IDF(the) = 0.33 \* 0 = 0
- TF-IDF(cat) = 0.17 \* 0.40 ≈ 0.068
- TF-IDF(sat) = 0.17 \* 0.40 ≈ 0.068
- TF-IDF(on) = 0.17 \* 0.40 ≈ 0.068
- TF-IDF(mat) = 0.17 \* 0.40 ≈ 0.068

#### 문서 2: "The dog sat on the mat"

- TF-IDF(the) = 0.33 \* 0 = 0
- TF-IDF(dog) = 0.17 \* 0.40 ≈ 0.068
- TF-IDF(sat) = 0.17 \* 0.40 ≈ 0.068
- TF-IDF(on) = 0.17 \* 0.40 ≈ 0.068
- TF-IDF(mat) = 0.17 \* 0.40 ≈ 0.068

#### 문서 3: "The cat chased the mouse"

- TF-IDF(the) = 0.4 \* 0 = 0
- TF-IDF(cat) = 0.2 \* 0.40 = 0.08
- TF-IDF(chased) = 0.2 \* 0.70 = 0.14
- TF-IDF(mouse) = 0.2 \* 0.40 = 0.08

#### 문서 4: "The

dog barked loudly"

- TF-IDF(the) = 0.25 \* 0 = 0
- TF-IDF(dog) = 0.25 \* 0.40 = 0.10
- TF-IDF(barked) = 0.25 \* 0.70 = 0.175
- TF-IDF(loudly) = 0.25 \* 0.70 = 0.175

#### 문서 5: "The mouse ran up the clock"

- TF-IDF(the) = 0.33 \* 0 = 0
- TF-IDF(mouse) = 0.17 \* 0.40 ≈ 0.068
- TF-IDF(ran) = 0.17 \* 0.70 ≈ 0.119
- TF-IDF(up) = 0.17 \* 0.70 ≈ 0.119
- TF-IDF(clock) = 0.17 \* 0.70 ≈ 0.119

### **요약**

- "the"와 같이 모든 문서에 공통으로 등장하는 단어는 IDF가 0이기 때문에 TF-IDF도 0이 되어 중요도가 낮습니다.
- "barked", "loudly", "chased" 등과 같이 드물게 등장하는 단어는 IDF가 높아져 TF-IDF 값도 높아집니다. 이는 문서에서 해당 단어의 중요도를 높게 평가하는 것을 의미합니다.
