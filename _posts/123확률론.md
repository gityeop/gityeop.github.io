## 확률론

기계학습에서 사용되는 손실함수(loss function)는 **데이터를 통계적으로 해석**하여 모델이 학습하는 방향을 결정한다. 손실함수는 모델이 예측한 결과와 실제 결과 사이의 차이를 측정하여, 이 차이를 최소화하는 방향으로 모델을 학습시킨다. 손실함수의 목적은 특정한 통계적 개념을 기반으로 하여 모델의 성능을 향상시키는 것이다.

예를 들어:

- L2 노름(L2 norm): L2 노름은 **예측 오차의 분산**을 최소화하는 방향으로 모델을 학습시킨다.
  - L2 노름은 왜 분산을 최소화하는 방향으로 학습하는가?
    $$
    L2_norm = \sum_{i=1}^{n} (y_i - \hat{y}_i)^2
    $$

$y_i$: 실제값, $\hat{y}_i$: 모델이 예측한 값

$(y_i - \hat{y}_i)^2$은 실제값과 예측값 간의 **차이**$(y_i - \hat{y}_i)$에 대해 **더 큰 패널티**($^2$)를 주겠다는 의미이다. 이는 실제값에서 더 멀리 떨어진 데이터일수록(분산이 큰 데이터일수록) 더 큰 패널티를 주어, 결과적으로 예측 오차의 분산을 최소화하는 방향으로 모델을 학습시킵니다.
![Image](https://i.imgur.com/n6bOlTi.png)

- 교차 엔트로피(Cross-Entropy): 교차 엔트로피는 **모델 예측의 불확실성**을 최소화하는 방향으로 학습합니다.
- 교차 엔트로피는 다음과 같은 수식으로 표현됩니다:
  $$
  H(p, q) = -\sum_{i} p(x_i) \log(q(x_i))
  $$
  $p(x_i)$: 실제 분포, $q(x_i)$: 모델이 예측한 분포

![Image](https://i.imgur.com/Pu3glpV.png)
$$\sum_{i} y_i (-\log(\hat y_i))$$
$y_i (-\log(\hat y_i))$에서 $y_{1}$이 1(참)이라고 할 때, $\hat y_i$이 1일 때(모델이 옳은 예측과 확신이 높은 경우) 가장 작은 값(0)을 가지고, 0.5 정도의 중간 값일 때(불확실한 경우) 상대적으로 큰 값을 가지고, 0일 때(확신을 가졌지만 틀렸을 경우) 가장 큰 값을 가진다.

따라서 교차 엔트로피는 모델이 잘못된 클래스를 예측할 확률을 줄이고, 불확실성을 최소화하는 방향으로 학습하게 된다.

---

**확률 분포 D** : 데이터 공간에 존재하는 모든 데이터 포인트들이 어떤 패턴이나 규칙에 따라 분포하고 있으며, **이 분포를 통계적으로 해석한 것**이 바로 **확률 분포 D**

확률 변수: 확률을 가지는 변수

- 로또복권의 1등 당첨 확률은 814만5060분의 1, 2등은 135만7510분의 1, 3등은 3만5724분의 1, 4등은 733분의 1, 5등 45분의 1
- 1, 2, 3, 4, 5등 처럼 확률을 가지고 있는 변수를 확률 변수라고 한다.

확률 변수는 로또 예시처럼 셀 수 있는 따라 **이산형 확률 변수(discrete)**와 실수 구간으로 정의되는 **연속형(continuous) 확률 변수**로 나뉜다

이산형 확률변수는 확률변수를 가질 수 있는 모든 경우의 수를 고려하여 확률을 더해서 모델링
=> 이산형 확률변수는 가능한 모든 값들에 대한 확률을 모두 더해서 전체 확률분포를 만듭니다.

- 로또의 1등~꽝의 모든 확률을 더하면 전체 확률 분포 1을 알 수 있음

확률 질량 함수 : 이산형 확률 변수의 특정 값에 대한 확률을 나타내는 함수, 특정한 값에 대한 확률의 **크기**

- 이산적이므로 각각의 값에 대한 확률을 덩어리(크기)로 볼 수 있음, 확률의 크기 => 질량

연속형 확률변수는 특정 구간에서 값이 나올 확률을 계산하기 위해, 확률 밀도 함수를 사용하여 그 구간을 적분

- "키가 (정확히) 170cm일 확률이 얼마인가?"라는 질문은 연속 확률 변수 특성상 옳지 않은 질문
- 대신에 “키가 169.5cm에서 170.5cm 사이일 확률은 얼마인가?”, “키가 170cm 이하일 확률은 얼마인가?"라는 구간에서 값이 나올 확률을 물어보는 질문이 유효한 질문

그러나 구간(interval) 하나를 정의하기 위해 숫자가 하나가 아닌 두 개가 필요하다는 점은 아무래도 불편하기 때문에, 이를 해결하기 위해 시작점을 음의 무한대($-\infty$)로 통일한 특수한 구간을 사용한다. 그리고 이러한 사건의 확률분포를 묘사하는 함수를 **누적분포함수(cumulative distribution function)**라고 한다

누적 분포 함수 (Cumulative Distribution Function, CDF)

누적 분포 함수 F(x) 는 **특정 값 이하의 확률을 나타내는 함수**입니다. 즉, X 가 x 이하일 확률을 나타냅니다:

$$ F(x) = P(X \leq x) $$

확률 밀도 함수와 누적 분포 함수의 관계

누적 분포 함수를 미분하면 확률 밀도 함수를 얻을 수 있다. 미분은 함수의 변화율을 나타내고, 누적 분포 함수를 미분한다는 것은(확률 밀도 함수) $x$ 근처에서 **새로운 데이터가 얼마나 많이 추가되는지**를 나타내는 것이다. 따라서 확률 밀도 함수의 높은 값은 그 구간에서 데이터가 더 많이 추가되어 밀집되어 있음을 의미한다.

---

**참고**

이산형, 연속형 확률 분포를 모두 가지는 확률 변수도 있음

-> 혼합분포(mixed distribution)

e.g. 통근 시간

지하철을 타는 사람들 중 일부는 특정 시간에 맞춰서 탑승. 지하철 출발 시간 -> 이산형 확률 변수

다른 교통 수단, 자가용 -> 도착 시간이 연속적으로 변할 수 있음

---

공동확률분포, 결합 분포 (Joint Probability Distribution)

공동확률분포(결합 분포)는 두 개 이상의 확률변수가 동시에 발생하는 확률을 나타냅니다. 예를 들어, 두 확률변수 X 와 Y 가 있을 때, 이들의 공동확률분포 P(X, Y) 는 X 와 Y 가 동시에 특정 값을 가질 확률을 나타냅니다.

- 예시: 만약 X 가 시험 점수이고 Y 가 학생의 학습 시간이라면, P(X = 80, Y = 5) 는 특정 학생이 시험에서 80점을 받고 학습 시간이 5시간일 확률을 나타냅니다. 이는 두 변수 간의 상관관계를 반영하여 동시에 특정 값을 가질 확률을 계산하는 방식입니다.

주변확률분포

주변확률분포(Marginal Probability Distribution)는 다변량 확률 분포(여러 개의 변수를 포함한 확률 분포)에서 특정 변수에 대한 개별 확률 분포를 의미합니다. 이는 다른 변수의 영향을 고려하지 않고, 관심 있는 변수에 대한 확률 분포를 계산할 수 있게 해줍니다.

- 예시: 만약 X 가 시험 점수이고 Y 가 학생의 학습 시간이라면, 주변 확률 분포 P(X) 는 학습 시간 Y 를 고려하지 않고, 학생들이 시험에서 받을 수 있는 점수 X 의 확률 분포를 의미합니다. 이때 주변 확률 분포 P(X) 는 Y 에 대해 적분하거나 합을 계산하여 구할 수 있습니다.

조건부확률분포(Conditional Probability Distribution)

조건부확률분포(Conditional Probability Distribution)는 어떤 사건이 주어졌을 때 다른 사건이 발생할 확률을 나타내는 분포입니다. 이는 특정 조건이 주어졌을 때의 상황에서 다른 사건이 발생할 가능성을 계산하는 데 사용됩니다.
이는 입력 변수 x 가 주어졌을 때, 출력 변수 y 가 특정 값을 가질 확률을 의미합니다.

- 예시: 날씨 x 가 맑을 때(주어진 조건) 우산을 들고 다니는 사람의 비율 y 를 구하는 것

우리는 조건부 확률 분포를 로지스틱 회귀와 소프트 맥스에서 볼 수 있다. 로지스틱 회귀는 이진 분류에서 사용된다. 예를 들어 입력 데이터 x가 주어졌을 때, 출력 y가 특정 클래스(여기서는 1)에 속할 확률을 다음과 같이 표현할 수 있다.
$$ P(y =1|x)$$

로지스틱 회귀의 수식은 아래와 같다.

$$
P(y = 1 | x) = \sigma(w^T x + b)
$$

![Image](https://i.imgur.com/aZ1zNFT.png)
시그모이드 함수 $\sigma(z)$의 출력은 0과 1사이의 값을 가지므로, 선형 모델 $w^T x + b$를 확률 값으로 변환해주는 역할을 한다.

마찬가지로 다중 클래스 분류에 사용되는 소프트맥스 함수는 입력 데이터 $x$가 주어졌을 때, 여러 개의 클래스 중 각 클래스에 속할 조건부 확률을 계산한다.

$$
P(y = i | x) = \frac{e^{w_i^T x}}{\sum_{j=1}^{k} e^{w_j^T x}}
$$

이때 softmax 함수에 자연상수 e를 사용하는 이유는

1. 미분이 용이하기 때문인 점
2. ![Image](https://i.imgur.com/Ut1mwtQ.png)
   $e^x$ 함수의 특성 상 출력값이 급격하게 커지거나 작아지기 때문에 클래스 간의 미세한 차이도 크게 반영되어 가능성이 높은 클래스에 대해 확실한 예측을 할 수 있도록 도와줍니다.
   - 예시: (3, 1, 1, 1, 1) -softmax-> (0.65, 0.086, 0.086, 0.086, 0.086)

---

머신러닝은 합성함수의 관점과 확률론의 관점에서 바라볼 수 있다.

합성함수의 관점에서 머신러닝은 입력 데이터를 여러 단계의 함수 변환을 통해 출력으로 매핑하는 과정으로 볼 수 있습니다.

확률론의 관점에서 머신러닝은 데이터와 모델의 불확실성을 다루고, 주어진 입력 데이터에 대한 출력의 확률분포를 학습하는 과정으로 볼 수 있습니다.

입력 데이터에 대해 출력의 확률분포를 학습하고 예측한다는 것은:

- 학습: 주어진 입력 데이터 x 에 대해, 가능한 출력 y 가 각각 얼마나 나올지를 학습합니다. 이는 각 출력 y 에 대한 확률을 학습하는 과정입니다.
- 예측: 학습된 모델을 사용하여 새로운 입력 데이터 x 가 주어졌을 때, 가능한 출력 y 들이 각각 얼마나 나올지를 예측합니다. 즉, 각 출력 y 에 대한 조건부 확률 $ P(y|x) $를 예측합니다.

---

기대값이 뭔가요?

- 확률 분포가 주어졌을 때, 확률 변수의 평균값을 계산하는 개념입니다.

$$
E[X] = \sum_{i} x_i \cdot P(X = x_i)
$$

- $x_i$는 $X$가 가질 수 있는 확률변수, $P(X = x_i)$는 그 값이 나올 확률
- 확률분포가 주어지면 데이터를 분석하는 데 사용 가능한 여러 종류의 통계적 범함수를 계산할 수 있음
  - 기대값을 통해 분산, 첨도, 공분산 등 여러 통계량을 계산할 수 있음

---

조건부 기대값

조건부 기대값은 기대값의 확장된 개념으로, 특정 조건이 주어진 상황에서의 기대값을 의미합니다. 즉, 확률 변수 X 에 대해 어떤 다른 변수 Y 가 특정 값을 가질 때, X 의 기대값을 계산하는 것입니다.

$$
\mathbb{E}[X | Y = y]
$$

회귀 문제에서 L2 손실 함수를 최소화하기 위해 조건부 기대값이 사용되는 이유

1. $L2 =  \mathbb{E}[Y - g(X)]^2 = \int_{-\infty}^{\infty} [y - g(X)]^2 f_{Y|X}(y|x) dy
$ 을 최소화

   - $f_{Y|X}(y|x)$는 주어진 $X$ 에 대한 $Y$의 조건부 확률 밀도 함수입니다.

1. 제곱항 전개 및 분해

   - 오차 제곱 항을 전개하여 식을 다음과 같이 변형:

   $$\mathbb{E}[Y - g(X)]^2 = \int_{-\infty}^{\infty} y^2 f_{Y|X}(y|x) dy - 2g(X) \int_{-\infty}^{\infty} y f_{Y|X}(y|x) dy + [g(X)]^2 \int_{-\infty}^{\infty} f_{Y|X}(y|x) dy$$

   이 식에서 세 가지 항으로 분해되었습니다:

   - 첫 번째 항: $\int_{-\infty}^{\infty} y^2 f_{Y|X}(y|x) dy$
   - 두 번째 항: $-2g(X) \int_{-\infty}^{\infty} y f_{Y|X}(y|x) dy$
   - 세 번째 항: $[g(X)]^2 \int_{-\infty}^{\infty} f_{Y|X}(y|x) dy$

1. 항들의 해석 및 최소화 과정

   - 첫 번째 항은 주어진 $X$와 관계없는 상수
   - 두 번째 항에서 $\int_{-\infty}^{\infty} y f_{Y|X}(y|x) dy$ 는 $Y$ 의 조건부 기대값 $\mathbb{E}[Y | X]$ 에 해당합니다.
   - 세 번째 항에서 $\int_{-\infty}^{\infty} f_{Y|X}(y|x) dy$ 는 모든 $y$ 값에 대한 확률 밀도의 적분이므로 1이 됩니다. 따라서 이 항은 $[g(X)]^2$ 로 단순화됩니다.

   이제 최소화 문제는 다음과 같은 형태가 됩니다:

   $\text{arg min}_{g(X)} \mathbb{E}[Y - g(X)]^2 = \text{arg min}_{g(X)} \left\{ -2g(X)\mathbb{E}(Y | X) + [g(X)]^2 \right\}$

1. 최적화

   - 이 식을 $g(X)$ 에 대해 미분하여 최소값을 구하면, 다음과 같은 조건이 성립합니다:

   $$\frac{\partial}{\partial g(X)} \left(-2g(X)\mathbb{E}[Y | X] + [g(X)]^2\right)$$

   $$= -2\mathbb{E}(Y | X) + 2g(X) = 0$$

   - 따라서, 최적의 $g(X)$ 는 $g(X) = \mathbb{E}[Y | X]$ 가 됩니다. 이는 L2 손실을 최소화하기 위해 모델 $g(X)$ 가 Y 의 조건부 기대값과 일치해야 함을 의미합니다.

---

몬테카를로 샘플링

- 기계학습의 많은 문제들은 확률분포를 명시적으로 모를 때가 대부분
- 확률분포를 모를 때 데이터를 이용하여 기대값을 계산하려면 몬테카를로(Monte Carlo) 샘플링 방법을 사용해야 한다.
- 몬테카를로는 이산형이든 연속형이든 상관없이 성립한다

샘플링의 의미

- 샘플링(Sampling): 전체 데이터나 확률분포에서 일부 값을 **무작위로 선택**하는 과정입니다. 이는 전체 분포의 특성을 이해하거나 계산을 단순화하는 데 사용됩니다.

몬테카를로 샘플링의 과정

1. 무작위 샘플링: 확률분포에서 무작위로 샘플을 추출합니다. 이때 이산형 확률분포든 연속형 확률분포든 상관없습니다.
2. 기대값 계산: 추출한 샘플들을 사용하여 기대값을 계산합니다. 추출한 샘플들이 확률분포를 대표한다고 가정하고, 이를 통해 전체 분포의 특성을 추정합니다.

---

참고 사이트

[누적 분포 함수](https://datascienceschool.net/02%20mathematics/06.04%20%ED%99%95%EB%A5%A0%EB%B6%84%ED%8F%AC%ED%95%A8%EC%88%98.html?highlight=%ED%99%95%EB%A5%A0%20%EB%B0%80%EB%8F%84%ED%95%A8%EC%88%98#id11)

[Softmax에서 왜 e를 쓸까](https://hyunlee103.tistory.com/84)

[Problem with proof of Conditional expectation as best predictor](https://stats.stackexchange.com/questions/71863/problem-with-proof-of-conditional-expectation-as-best-predictor)
